{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91748d70-fe9b-41d7-8def-febf5b284994",
   "metadata": {},
   "source": [
    "# SNLP project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53aa1cab-f3e4-4361-8eba-fd10c277077f",
   "metadata": {},
   "source": [
    "## Ingredient substitution task \n",
    "\n",
    "**Objective:**\n",
    "\n",
    "Produce some suggestions for substitution for certain ingredients, e,g, “vegan” and “pesto pasta” might give us “tofu”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b7bb3f5-c9e5-4952-9142-f378e41c9a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sannalun/opt/anaconda3/envs/spoonacular/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import download\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d09a80a4-0058-430a-9a42-48d7a91a8ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/sannalun/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "download('stopwords')\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5fa1bce-a1c6-4bad-82fa-e89d424e3fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/sannalun/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "420bd8a7-42da-4bb1-929f-5f6ba08d1b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/sannalun/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/sannalun/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/omw-1.4.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02451eb1-88c6-42fe-b254-803de5cecf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/cleaneddata.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf468396-a8ba-4c45-899a-fd395178f5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fa3dfb-6b04-4cde-8206-08df7f4e24e3",
   "metadata": {},
   "source": [
    "## 1. Text preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f993f00-d851-477c-b636-fbdda5c3b8b7",
   "metadata": {},
   "source": [
    "### 1.1 Drop column we don't need and renaming columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecb3597d-e788-465f-b5d6-d4086c3ef605",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"healthScore\", \"pricePerServing\", \"readyInMinutes\", \"servings\"], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16dc70f4-c3bd-4f4f-ad6f-100fa5ca7c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\n",
    "    \"glutenFree\": \"gluten-free\", \n",
    "    \"dairyFree\": \"dairy-free\", \n",
    "    \"veryHealthy\":\"very-healthy\", \n",
    "    \"veryPopular\": \"very-popular\", \n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2c557f-44fa-4909-b892-229e6284b699",
   "metadata": {},
   "source": [
    "### 1.2 Transform the TRUE classification labels to class name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e91d9e6b-a984-4a64-87ad-fc9c3601a3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['vegetarian', \n",
    "           'vegan', \n",
    "           'gluten-free', \n",
    "           'dairy-free', \n",
    "           'very-healthy', \n",
    "           'cheap', \n",
    "           'very-popular', \n",
    "           'sustainable']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1119c718-42af-40af-847a-0d92a9bf1d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in classes:\n",
    "    df[c] = df[c].replace(to_replace=[True, False], value=[c, np.nan])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "921bd1ff-833f-43b1-94fd-c44ffca26993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>instructions</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>ingredient types</th>\n",
       "      <th>diets</th>\n",
       "      <th>vegetarian</th>\n",
       "      <th>vegan</th>\n",
       "      <th>gluten-free</th>\n",
       "      <th>dairy-free</th>\n",
       "      <th>very-healthy</th>\n",
       "      <th>cheap</th>\n",
       "      <th>very-popular</th>\n",
       "      <th>sustainable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>orange fig teacake with caramel glaze</td>\n",
       "      <td>orange fig teacake with caramel glaze is a veg...</td>\n",
       "      <td>you will need a 9  springform pan  or a cake ...</td>\n",
       "      <td>ap flour; baking powder; cardamom; eggs; fresh...</td>\n",
       "      <td>Beverages Milk Eggs Other Dairy Spices and Sea...</td>\n",
       "      <td>lacto ovo vegetarian</td>\n",
       "      <td>vegetarian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>poached eggs on a bed of fried mushrooms and c...</td>\n",
       "      <td>poached eggs on a bed of fried mushrooms and c...</td>\n",
       "      <td>in a frying pan heat up oil then add mushroom...</td>\n",
       "      <td>bread; butter; eggs; eggs; mushrooms; oil; sal...</td>\n",
       "      <td>Beverages Milk Eggs Other Dairy Spices and Sea...</td>\n",
       "      <td>lacto ovo vegetarian</td>\n",
       "      <td>vegetarian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pandan chiffon cake</td>\n",
       "      <td>for 26 cents per serving   this recipe covers ...</td>\n",
       "      <td>preheat the oven to 170c  blend the pandan le...</td>\n",
       "      <td>all purpose flour; bay leaves; coconut milk; c...</td>\n",
       "      <td>Ethnic Foods Produce Spices and Seasonings Bev...</td>\n",
       "      <td>dairy free; lacto ovo vegetarian</td>\n",
       "      <td>vegetarian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dairy-free</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pork chop with honey  mustard and apples</td>\n",
       "      <td>pork chop with honey  mustard and apples might...</td>\n",
       "      <td>pre heat your oven to 200c   400f  line a roa...</td>\n",
       "      <td>apples; dijon mustard; garlic cloves; honey; j...</td>\n",
       "      <td>Meat Spices and Seasonings Condiments Oil Vine...</td>\n",
       "      <td>gluten free; dairy free; paleolithic; primal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gluten-free</td>\n",
       "      <td>dairy-free</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>beet gnocchi with steak and brown butter sauce</td>\n",
       "      <td>the recipe beet gnocchi with steak and brown b...</td>\n",
       "      <td>cooking beets heat oven to 400 degrees wash be...</td>\n",
       "      <td>gnocchi; beets; olive oil; s p; goat cheese; r...</td>\n",
       "      <td>Produce Spices and Seasonings Meat Spices and ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0              orange fig teacake with caramel glaze   \n",
       "1  poached eggs on a bed of fried mushrooms and c...   \n",
       "2                                pandan chiffon cake   \n",
       "3           pork chop with honey  mustard and apples   \n",
       "4     beet gnocchi with steak and brown butter sauce   \n",
       "\n",
       "                                             summary  \\\n",
       "0  orange fig teacake with caramel glaze is a veg...   \n",
       "1  poached eggs on a bed of fried mushrooms and c...   \n",
       "2  for 26 cents per serving   this recipe covers ...   \n",
       "3  pork chop with honey  mustard and apples might...   \n",
       "4  the recipe beet gnocchi with steak and brown b...   \n",
       "\n",
       "                                        instructions  \\\n",
       "0   you will need a 9  springform pan  or a cake ...   \n",
       "1   in a frying pan heat up oil then add mushroom...   \n",
       "2   preheat the oven to 170c  blend the pandan le...   \n",
       "3   pre heat your oven to 200c   400f  line a roa...   \n",
       "4  cooking beets heat oven to 400 degrees wash be...   \n",
       "\n",
       "                                         ingredients  \\\n",
       "0  ap flour; baking powder; cardamom; eggs; fresh...   \n",
       "1  bread; butter; eggs; eggs; mushrooms; oil; sal...   \n",
       "2  all purpose flour; bay leaves; coconut milk; c...   \n",
       "3  apples; dijon mustard; garlic cloves; honey; j...   \n",
       "4  gnocchi; beets; olive oil; s p; goat cheese; r...   \n",
       "\n",
       "                                    ingredient types  \\\n",
       "0  Beverages Milk Eggs Other Dairy Spices and Sea...   \n",
       "1  Beverages Milk Eggs Other Dairy Spices and Sea...   \n",
       "2  Ethnic Foods Produce Spices and Seasonings Bev...   \n",
       "3  Meat Spices and Seasonings Condiments Oil Vine...   \n",
       "4  Produce Spices and Seasonings Meat Spices and ...   \n",
       "\n",
       "                                          diets  vegetarian vegan  \\\n",
       "0                          lacto ovo vegetarian  vegetarian   NaN   \n",
       "1                          lacto ovo vegetarian  vegetarian   NaN   \n",
       "2              dairy free; lacto ovo vegetarian  vegetarian   NaN   \n",
       "3  gluten free; dairy free; paleolithic; primal         NaN   NaN   \n",
       "4                                           NaN         NaN   NaN   \n",
       "\n",
       "   gluten-free  dairy-free very-healthy cheap very-popular  sustainable  \n",
       "0          NaN         NaN          NaN   NaN          NaN          NaN  \n",
       "1          NaN         NaN          NaN   NaN          NaN          NaN  \n",
       "2          NaN  dairy-free          NaN   NaN          NaN          NaN  \n",
       "3  gluten-free  dairy-free          NaN   NaN          NaN          NaN  \n",
       "4          NaN         NaN          NaN   NaN          NaN          NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd104963-10c1-4695-9e89-2f035b909ed6",
   "metadata": {},
   "source": [
    "### 1.3 Creating two copies of the diets and ingredients columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bfd3d4-3275-461f-88bc-633afc447625",
   "metadata": {},
   "source": [
    "The ingredients and diets are going to be important for this tasks. To make our model more flexible, we will expand the vocabularies in these categories. \n",
    "\n",
    "For diets, we want to include both `\"gluten free\"` and `\"gluten-free\"` in the corpus. For ingredients, we want to include both `\"extra virgin olive oil\"` and `\"extra\", \"virgin\", \"olive\", \"oil\"`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3080ccc9-b8df-463b-a8a2-089a6dcc6d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"ingredient split\"] = df[\"ingredients\"].str.replace(\"; \", \" \")\n",
    "df[\"diet split\"] = df[\"diets\"].str.replace(\" \", \"-\").str.replace(\";-\", \"; \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26baea6d-1647-435b-876b-940dae2a4b15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>instructions</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>ingredient types</th>\n",
       "      <th>diets</th>\n",
       "      <th>vegetarian</th>\n",
       "      <th>vegan</th>\n",
       "      <th>gluten-free</th>\n",
       "      <th>dairy-free</th>\n",
       "      <th>very-healthy</th>\n",
       "      <th>cheap</th>\n",
       "      <th>very-popular</th>\n",
       "      <th>sustainable</th>\n",
       "      <th>diet split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>orange fig teacake with caramel glaze</td>\n",
       "      <td>orange fig teacake with caramel glaze is a veg...</td>\n",
       "      <td>you will need a 9  springform pan  or a cake ...</td>\n",
       "      <td>ap flour; baking powder; cardamom; eggs; fresh...</td>\n",
       "      <td>Beverages Milk Eggs Other Dairy Spices and Sea...</td>\n",
       "      <td>lacto ovo vegetarian</td>\n",
       "      <td>vegetarian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lacto-ovo-vegetarian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>poached eggs on a bed of fried mushrooms and c...</td>\n",
       "      <td>poached eggs on a bed of fried mushrooms and c...</td>\n",
       "      <td>in a frying pan heat up oil then add mushroom...</td>\n",
       "      <td>bread; butter; eggs; eggs; mushrooms; oil; sal...</td>\n",
       "      <td>Beverages Milk Eggs Other Dairy Spices and Sea...</td>\n",
       "      <td>lacto ovo vegetarian</td>\n",
       "      <td>vegetarian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lacto-ovo-vegetarian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pandan chiffon cake</td>\n",
       "      <td>for 26 cents per serving   this recipe covers ...</td>\n",
       "      <td>preheat the oven to 170c  blend the pandan le...</td>\n",
       "      <td>all purpose flour; bay leaves; coconut milk; c...</td>\n",
       "      <td>Ethnic Foods Produce Spices and Seasonings Bev...</td>\n",
       "      <td>dairy free; lacto ovo vegetarian</td>\n",
       "      <td>vegetarian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dairy-free</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dairy-free; lacto-ovo-vegetarian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pork chop with honey  mustard and apples</td>\n",
       "      <td>pork chop with honey  mustard and apples might...</td>\n",
       "      <td>pre heat your oven to 200c   400f  line a roa...</td>\n",
       "      <td>apples; dijon mustard; garlic cloves; honey; j...</td>\n",
       "      <td>Meat Spices and Seasonings Condiments Oil Vine...</td>\n",
       "      <td>gluten free; dairy free; paleolithic; primal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gluten-free</td>\n",
       "      <td>dairy-free</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gluten-free; dairy-free; paleolithic; primal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>beet gnocchi with steak and brown butter sauce</td>\n",
       "      <td>the recipe beet gnocchi with steak and brown b...</td>\n",
       "      <td>cooking beets heat oven to 400 degrees wash be...</td>\n",
       "      <td>gnocchi; beets; olive oil; s p; goat cheese; r...</td>\n",
       "      <td>Produce Spices and Seasonings Meat Spices and ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0              orange fig teacake with caramel glaze   \n",
       "1  poached eggs on a bed of fried mushrooms and c...   \n",
       "2                                pandan chiffon cake   \n",
       "3           pork chop with honey  mustard and apples   \n",
       "4     beet gnocchi with steak and brown butter sauce   \n",
       "\n",
       "                                             summary  \\\n",
       "0  orange fig teacake with caramel glaze is a veg...   \n",
       "1  poached eggs on a bed of fried mushrooms and c...   \n",
       "2  for 26 cents per serving   this recipe covers ...   \n",
       "3  pork chop with honey  mustard and apples might...   \n",
       "4  the recipe beet gnocchi with steak and brown b...   \n",
       "\n",
       "                                        instructions  \\\n",
       "0   you will need a 9  springform pan  or a cake ...   \n",
       "1   in a frying pan heat up oil then add mushroom...   \n",
       "2   preheat the oven to 170c  blend the pandan le...   \n",
       "3   pre heat your oven to 200c   400f  line a roa...   \n",
       "4  cooking beets heat oven to 400 degrees wash be...   \n",
       "\n",
       "                                         ingredients  \\\n",
       "0  ap flour; baking powder; cardamom; eggs; fresh...   \n",
       "1  bread; butter; eggs; eggs; mushrooms; oil; sal...   \n",
       "2  all purpose flour; bay leaves; coconut milk; c...   \n",
       "3  apples; dijon mustard; garlic cloves; honey; j...   \n",
       "4  gnocchi; beets; olive oil; s p; goat cheese; r...   \n",
       "\n",
       "                                    ingredient types  \\\n",
       "0  Beverages Milk Eggs Other Dairy Spices and Sea...   \n",
       "1  Beverages Milk Eggs Other Dairy Spices and Sea...   \n",
       "2  Ethnic Foods Produce Spices and Seasonings Bev...   \n",
       "3  Meat Spices and Seasonings Condiments Oil Vine...   \n",
       "4  Produce Spices and Seasonings Meat Spices and ...   \n",
       "\n",
       "                                          diets  vegetarian vegan  \\\n",
       "0                          lacto ovo vegetarian  vegetarian   NaN   \n",
       "1                          lacto ovo vegetarian  vegetarian   NaN   \n",
       "2              dairy free; lacto ovo vegetarian  vegetarian   NaN   \n",
       "3  gluten free; dairy free; paleolithic; primal         NaN   NaN   \n",
       "4                                           NaN         NaN   NaN   \n",
       "\n",
       "   gluten-free  dairy-free very-healthy cheap very-popular  sustainable  \\\n",
       "0          NaN         NaN          NaN   NaN          NaN          NaN   \n",
       "1          NaN         NaN          NaN   NaN          NaN          NaN   \n",
       "2          NaN  dairy-free          NaN   NaN          NaN          NaN   \n",
       "3  gluten-free  dairy-free          NaN   NaN          NaN          NaN   \n",
       "4          NaN         NaN          NaN   NaN          NaN          NaN   \n",
       "\n",
       "                                     diet split  \n",
       "0                          lacto-ovo-vegetarian  \n",
       "1                          lacto-ovo-vegetarian  \n",
       "2              dairy-free; lacto-ovo-vegetarian  \n",
       "3  gluten-free; dairy-free; paleolithic; primal  \n",
       "4                                           NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665952df-55f5-4bb3-b143-73eda5c981de",
   "metadata": {},
   "source": [
    "## 2. Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5fdaa8-b8dd-4501-a4bf-18cd4168f949",
   "metadata": {},
   "source": [
    "Here I use the Gensim library to create a word2vec embedding. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd4fa68-e06f-4e1e-a091-3743a19a06e3",
   "metadata": {},
   "source": [
    "Reference: \n",
    "- Gensim Word2Vec documentation: https://radimrehurek.com/gensim/models/word2vec.html\n",
    "- DAS, P, 2020. How to train word2vec model using gensim library [online]. Medium. [viewed 26/03/2020]. Available from: https://medium.com/swlh/how-to-train-word2vec-model-using-gensim-library-115b35440c90"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc7547c-cc85-445d-8ae1-0c4a4f96fbdb",
   "metadata": {},
   "source": [
    "#### 2.1 Trainsform data into the required format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "874034ff-ce4b-414b-be9a-c690e580e7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainWord2Vec = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2844f0e-98bc-4be5-8b1f-cd3fd076da32",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sentence(object):\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        self.df = df\n",
    "        self.n_rows = df.shape[0]\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for n in range(self.n_rows):\n",
    "            row = self.df.iloc[n]\n",
    "            sentence : List[str] = []\n",
    "            for i, cell in enumerate(row):\n",
    "                if type(cell) == str:\n",
    "                    sent = cell.split(\"; \") if df.columns[i] in [\"ingredients\", \"diets\"] else cell.split()\n",
    "                    sent = [w.lower() for w in sent if w not in stop_words]\n",
    "                    if len(sent) > 0: sent[-1] = self.lemmatizer.lemmatize(sent[-1])\n",
    "                    sentence += sent\n",
    "            yield sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fe1c9e88-af48-47fa-a155-ae1806673432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiase\n",
    "if trainWord2Vec:\n",
    "    sentences = Sentence(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74cb17bc-b056-4dad-be8f-e031da95d769",
   "metadata": {},
   "source": [
    "### 2.2 Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8a70df-7059-42e4-b4ee-7570abf6b22e",
   "metadata": {},
   "source": [
    "After experimenting with different values, the following setup seem to give reasonable results:\n",
    "- vector size 300\n",
    "- min count 1\n",
    "- window 5\n",
    "- epoch 30\n",
    "\n",
    "Training time: ~80 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ad47dae4-43ff-4eaa-8d7f-191314cbbd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "if trainWord2Vec:\n",
    "    start = time.time()\n",
    "    model = Word2Vec(\n",
    "        sentences, \n",
    "        min_count=1,\n",
    "        vector_size=300, \n",
    "        workers=2,\n",
    "        window=2,\n",
    "        epochs=30, \n",
    "        sg=0\n",
    "    )\n",
    "    end = time.time()\n",
    "    model.save(\"word2vec.model\")\n",
    "    print(f\"Training comleted in {end-start}s.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88226908-c113-45cd-b1ba-950eacb2ce90",
   "metadata": {},
   "source": [
    "### 2.3 Generate ingredient suggestions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de06d08e-45df-4b61-abd2-10696d9abf2f",
   "metadata": {},
   "source": [
    "To get ingredient suggestions, we will provide the desired postiive (and maybe also negetive) keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ddec5d15-d27a-4414-a53c-380a5550ef3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec.load(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "45730190-b56d-4874-afb6-981ef09a2b1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('feta', 0.4106769561767578),\n",
       " ('pescatarian', 0.40386947989463806),\n",
       " ('alfredo', 0.39441919326782227),\n",
       " ('fresh mozzarella cheese', 0.3637278079986572),\n",
       " ('gorgonzola', 0.3603726327419281),\n",
       " ('arugula', 0.354171484708786),\n",
       " ('dressing', 0.3513053059577942),\n",
       " ('fetan', 0.34398210048675537),\n",
       " ('salad', 0.3417564332485199),\n",
       " ('dairy', 0.33915770053863525),\n",
       " ('goat’s', 0.3384309411048889),\n",
       " ('free', 0.3335084021091461),\n",
       " ('rigate', 0.3308608829975128),\n",
       " ('pappardelle', 0.3304375410079956),\n",
       " ('garlicky', 0.3240084946155548),\n",
       " ('orzo', 0.31973889470100403),\n",
       " ('pilaf', 0.3195817768573761),\n",
       " ('spaghetti', 0.31901875138282776),\n",
       " ('gluten-free', 0.31660717725753784),\n",
       " ('mozzarellan', 0.31027910113334656)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=[\"vegan\", \"pesto\", \"pasta\"], topn=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79848c90-d366-427f-aae2-66f081eed701",
   "metadata": {},
   "source": [
    "The results are satisfactory. For example, even though \"feta\" and \"fresh mozzarella cheese\" are not vegan, they are somewhat resonable suggestions. There are at least no meat on the list. \n",
    "\n",
    "However, we also observed that there are a lot of non-ingredient words in the list of suggestions, such as \"free\". Therefore, we decided to find out to exclude suggestions that are not in the list of ingredients. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edc650b-90ab-4cb5-8b5f-938312d103fc",
   "metadata": {},
   "source": [
    "### 2.4 Improved ingredient suggestion generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60540c5-39d7-4f50-9004-f5b18009146c",
   "metadata": {},
   "source": [
    "Our strategy is:\n",
    "1. Obtain a list of candicate incredients, save it in a list\n",
    "2. Generate suggestions like above, but filter out suggestions that are not in the ingredient list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "216b86c5-c08e-4620-b49a-e64bbb3110de",
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredients = df[\"ingredients\"].to_list()\n",
    "# ingredients_split = df[\"ingredient split\"].to_list()\n",
    "\n",
    "all_ingredients = []\n",
    "for i in ingredients: \n",
    "    items = i.split(\"; \")\n",
    "    all_ingredients += items\n",
    "\n",
    "# for i in ingredients_split: \n",
    "#     items = i.split()\n",
    "#     all_ingredients += items\n",
    "\n",
    "all_ingredients = list(set(all_ingredients))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6a56a512-16ad-454e-a5b5-32ae8c89eb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ingredients(ingredients: List[str], \n",
    "                    original_recipe: List[str], \n",
    "                    positive: List[str], \n",
    "                    negative: List[str] = [], \n",
    "                    topn=20):\n",
    "    \n",
    "    pos = original_recipe.split() + positive*3\n",
    "    candidates = model.wv.most_similar(positive=pos, negative=negative*2, topn=200)\n",
    "    \n",
    "    substitutions = []\n",
    "    for ingredient_name, _ in candidates:\n",
    "        if len(substitutions) >= topn:\n",
    "            break\n",
    "        if ingredient_name in ingredients:\n",
    "            substitutions.append(ingredient_name)\n",
    "    return substitutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1a32d9fa-294c-4add-b20a-8dbe1c3e9353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feta',\n",
       " 'mushroom',\n",
       " 'bulgur',\n",
       " 'gorgonzola',\n",
       " 'arugula',\n",
       " 'mayo',\n",
       " 'orzo',\n",
       " 'fresh mozzarella cheese',\n",
       " 'chickpeas',\n",
       " 'cornbread',\n",
       " 'crepes',\n",
       " 'honey',\n",
       " 'bread',\n",
       " 'turkey',\n",
       " 'broccoli',\n",
       " 'buckwheat',\n",
       " 'chipotle',\n",
       " 'cauliflower',\n",
       " 'baguettes']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ingredients(all_ingredients, \n",
    "                original_recipe=\"pesto chicken pasta\", \n",
    "                positive=[\"vegan\"], \n",
    "                negative=[], topn=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa56ba4-23db-4087-9632-27a65b1d368f",
   "metadata": {},
   "source": [
    "## 3. BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066cfa87-3c4b-4b34-ba6b-5c1739307a86",
   "metadata": {},
   "source": [
    "### 3.1 Pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2ded2cf2-532a-4bcb-bd37-18de23858a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel, FillMaskPipeline\n",
    "import torch\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "40c9be43-e362-4861-bc75-278f5d76dae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "fill = pipeline(\"fill-mask\", \n",
    "                model=\"bert-base-uncased\", \n",
    "                tokenizer=tokenizer, \n",
    "                top_k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "1ab0a0be-90cf-434f-bfa9-59ab68088349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['and',\n",
       " '&',\n",
       " 'salad',\n",
       " 'with',\n",
       " '-',\n",
       " ',',\n",
       " 'fried',\n",
       " ':',\n",
       " 'or',\n",
       " 'chicken',\n",
       " '/',\n",
       " 'homemade',\n",
       " 'cheese',\n",
       " 'fish',\n",
       " 'rice',\n",
       " 'style',\n",
       " 'for',\n",
       " 'sliced',\n",
       " 'italian',\n",
       " 'chile']"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = fill(f\"vegan pesto {fill.tokenizer.mask_token} pasta\")\n",
    "[''.join(r['token_str'].split()) for r in results]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bb3aa7-1f50-45dd-9e8b-ed116730c109",
   "metadata": {},
   "source": [
    "### 3.2 Custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ccb729d4-7fa3-4012-ac87-cb1d43b1d478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set train to True to train model \n",
    "trainBert = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "bcb3bb07-0df6-4b71-a465-fbf8685b902e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import ByteLevelBPETokenizer\n",
    "from transformers import RobertaModel, RobertaTokenizerFast, RobertaConfig, RobertaForMaskedLM, AdamW\n",
    "import os \n",
    "from tqdm.auto import tqdm\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194e53d3-5aaa-49bf-a977-f0831fe4a169",
   "metadata": {},
   "source": [
    "#### Create the text file for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "75ddeafe-7c1d-437a-90a4-622cc78ed6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.apply(lambda x: \" \".join([cell for cell in x if type(cell)==str]), axis=1)\n",
    "\n",
    "recipes = \"\\n\".join(df1.to_list())\n",
    "with open(\"recipes.txt\", 'w', encoding=\"utf-8\") as f:\n",
    "    f.write(recipes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8caf09-0fd1-467f-90fd-15b5fbd60070",
   "metadata": {},
   "source": [
    "#### Train tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "da15b191-bff1-41a0-9cd0-cd65b7394396",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_path = \"recipe_tokenizer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "52b98534-5313-42e0-9c51-a2724c114586",
   "metadata": {},
   "outputs": [],
   "source": [
    "if trainBert:\n",
    "    tokenizer = ByteLevelBPETokenizer()\n",
    "    \n",
    "    # Train the tokenizer with text\n",
    "    tokenizer.train(files=[\"recipes.txt\"], \n",
    "                vocab_size=30_522, \n",
    "                min_frequency=1, \n",
    "                special_tokens=['<s>', '<pad>', '</s>', '<unk>', '<mask>'])\n",
    "    os.mkdir(\"recipe_tokenizer\")\n",
    "    tokenizer.save_model(tokenizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "4ae3ccde-d9fe-424e-9239-83b15a8517ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizerFast.from_pretrained(tokenizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c4c5ef71-a6c3-4318-9fe0-72a9bce096b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('recipe_tokenizer/tokenizer_config.json',\n",
       " 'recipe_tokenizer/special_tokens_map.json',\n",
       " 'recipe_tokenizer/vocab.json',\n",
       " 'recipe_tokenizer/merges.txt',\n",
       " 'recipe_tokenizer/added_tokens.json',\n",
       " 'recipe_tokenizer/tokenizer.json')"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(tokenizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "8af892ef-4914-4318-9c60-f41b7dbedebe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [0, 8327, 974, 2], 'attention_mask': [1, 1, 1, 1]}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"pesto pasta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a3a36b-349f-432b-b57c-18ed517244c0",
   "metadata": {},
   "source": [
    "### Input pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "911c9b60-d15c-4e24-a443-51d34c6f3943",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlm(tensor):\n",
    "    \"\"\"\n",
    "    input: tensor of sentences\n",
    "    output: tensor of sentences with masks words\n",
    "    \"\"\"\n",
    "    rand = torch.rand(tensor.shape)\n",
    "    mask_arr = (rand < 0.15) * (tensor > 2)\n",
    "    for i in range(tensor.shape[0]):\n",
    "        selection = torch.flatten(mask_arr[i].nonzero()).tolist()\n",
    "        tensor[i, selection] = 4 # mask token\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "a34bfb4d-adb3-48f2-a46c-eaa86ea99908",
   "metadata": {},
   "outputs": [],
   "source": [
    "if trainBert:\n",
    "    input_ids = []\n",
    "    attn_mask = [] \n",
    "    labels = []\n",
    "\n",
    "    with open(\"recipes.txt\", 'r', encoding='utf-8') as f:\n",
    "        lines = f.read().split('\\n')\n",
    "\n",
    "    sample = tokenizer(lines, \n",
    "                       max_length=512, \n",
    "                       padding=\"max_length\", \n",
    "                       truncation=True, \n",
    "                       return_tensors='pt')\n",
    "    labels.append(sample.input_ids)\n",
    "    attn_mask.append(sample.attention_mask)\n",
    "    input_ids.append(mlm(sample.input_ids.detach().clone()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "405f1c94-ae78-401a-a14b-f9590267575c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.encodings['input_ids'].shape[0]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return {key: tensor[i] for key, tensor in self.encodings.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "bd34017a-ac81-42ad-b571-e2e3ae92a363",
   "metadata": {},
   "outputs": [],
   "source": [
    "if trainBert:\n",
    "    # set up for training\n",
    "    input_ids = torch.cat(input_ids)\n",
    "    attn_mask = torch.cat(attn_mask)\n",
    "    labels = torch.cat(labels)\n",
    "    \n",
    "    encodings = {\n",
    "    'input_ids': input_ids,\n",
    "    'attention_mask': attn_mask,\n",
    "    'labels': labels\n",
    "    }\n",
    "    \n",
    "    dataset = Dataset(encodings)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "    \n",
    "    config = RobertaConfig(\n",
    "    vocab_size = tokenizer.vocab_size,\n",
    "    max_position_embeddings=514, \n",
    "    hidden_size = 768, \n",
    "    num_attention_heads=12, \n",
    "    num_hidden_layers= 6, \n",
    "    type_vocab_size = 1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "4f6f2902-5046-4239-a590-407210c07201",
   "metadata": {},
   "outputs": [],
   "source": [
    "if trainBert:\n",
    "    device = torch.device(\"cuda\"  if torch.cuda.is_available() else \"cpu\")\n",
    "    optim = AdamW(model.parameters(), lr=1e-4)\n",
    "    model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "730a63d5-6550-4a8d-b5cc-ed571a4a3449",
   "metadata": {},
   "outputs": [],
   "source": [
    "if trainBert:\n",
    "    loop = tqdm(dataloader, leave=True)\n",
    "\n",
    "    for batch in loop:\n",
    "        optim.zero_grad()\n",
    "\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        loop.set_description(f\"Epoch: {epochs}\")\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "    \n",
    "    model.save_pretrained('./model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d76d02-3c5b-4322-b544-6e94ae304706",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "ed95105d-3180-4c61-934c-f411b6b96109",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./model were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at ./model and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = RobertaModel.from_pretrained(\"./model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "7dce7419-22d4-449c-9795-fdf7428682ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' ',\n",
       " ' and',\n",
       " ';',\n",
       " ' the',\n",
       " ' to',\n",
       " ' a',\n",
       " ' with',\n",
       " '<pad>',\n",
       " ' of',\n",
       " '  ',\n",
       " ' is',\n",
       " ' for',\n",
       " ' in',\n",
       " ' recipe',\n",
       " ' this',\n",
       " ' minutes',\n",
       " '-',\n",
       " 'g',\n",
       " ' gluten',\n",
       " 'free']"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill = pipeline(\"fill-mask\", \n",
    "                model=\"model\", \n",
    "                tokenizer=\"recipe_tokenizer\", \n",
    "                top_k=20)\n",
    "\n",
    "searchString = f\"vegan pesto {fill.tokenizer.mask_token} pasta\"\n",
    "ingredients = [c['token_str'] for c in fill(searchString)]\n",
    "ingredients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcbd3c8-dadc-4e2f-8bc5-0f6100059a0f",
   "metadata": {},
   "source": [
    "## Using pre-trained embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "35c036ee-5ebc-4249-b1f4-53c788720409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def most_similar(word, topn=5):\n",
    "    word = nlp.vocab[str(word)]\n",
    "    \n",
    "    # for w in word.vocab:\n",
    "        # print(w.is_lower, word.is_lower, w.prob)\n",
    "    queries = [\n",
    "        w for w in word.vocab \n",
    "        if w.is_lower == word.is_lower and w.prob >= -15 and np.count_nonzero(w.vector)\n",
    "    ]\n",
    "\n",
    "    by_similarity = sorted(queries, key=lambda w: word.similarity(w), reverse=True)\n",
    "    return [(w.lower_,w.similarity(word)) for w in by_similarity[:topn+1] if w.lower_ != word.lower_]\n",
    "\n",
    "most_similar(\"dog\", topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "d5502378-2fa2-456f-ae2a-cb8900c4dfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [s for s in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "7d7b7976-b1a1-40f2-9b02-2dc5563146f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'roasted butternut squash bisque roasted butternut squash bisque could gluten free lacto ovo vegetarian recipe looking recipe serves 6 costs 5 1 per serving one serving contains 575 calories 6g protein 28g fat mixture coursely garlic salt bay leaves handful ingredients takes make recipe delicious recipe foodista 1 fans preparation plate recipe takes approximately approximately 45 minutes works well expensive soup taking factors account recipe earns spoonacular score 63 solid users liked recipe also liked roasted butternut squash bisque frangelico roasted butternut squash bisque sage cream butternut squash bisque garlic broth add ingredients stock bring boil reduce heat cover simmer 30 minutes strain cheesecloth use immediately soup freeze individual portions tip freezing broth ice cube trays allows use small portions time butternut squash soup cut squash half lengthwise scoop seeds quarter squash large place olive oil coated squash flesh side tray roasting roast top rack oven 425 degrees tender roughly 45 50 minutes sure use cookie tray least 1 2 inch lip squash give lot water pour generous amount olive oil cover bottom stock pot heat low medium heat add chopped onion cook translucent clean fennel bulb fern fern top finely leafed portion fennel cold water pat dry detach fern stems discarding stems pithy chop bulb discarding tough outer layer add chopped fennel bulb onion continue saut low heat stirring occasionally turn heat medium add 1 cup white wine onion fennel cook alcohol burns approximately 4 5 minutes seed quarter red bell peppers coat olive oil place cookie sheet flash side roast 20 minutes skins blistered started brown trick removing skins peppers remove peppers oven immediately place bowl cover cellophane let sit least 15 minutes skins peel easily meanwhile add vegetable garlic broth pot onions fennel cover bring slow boil mince several sage leaves add pot reduce simmer squash done scoop flesh peel add pot add remaining cup wine add cinnamon cayenne pepper curry powder ginger powder remove soup heat puree hand mixer immersion blender thoroughly mixed transfer food processor smoother texture many recipes call cream point create silkiness want bisque type soup little extra work eliminate need dairy products get creamy smooth texture without fat even silkier texture go one step work soup sieve spoon one completely okay texture soup without extra step garnish bowl leftover fennel fern enjoy extra virgin olive oil butter sweet onions fennel bulb butternut squash red bell pepper white wine fresh sage ginger powder cayenne pepper curry powder broth broth garlic bay leaves olive oil dried sage dried thyme oregano salt Produce Spices Seasonings Alcoholic Beverages Milk Eggs Other Dairy Spices Seasonings Produce Canned Jarred Oil Vinegar Salad Dressing gluten free lacto ovo vegetarian primal gluten-free lacto-ovo-vegetarian primal vegetarian gluten-free'"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "7ec30507-2e44-4c57-9f6d-4b186bb04c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('e', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "txt = \" \".join(test[0])\n",
    " \n",
    "# sent_tokenize is one of instances of\n",
    "# PunktSentenceTokenizer from the nltk.tokenize.punkt module\n",
    " \n",
    "tokenized = sent_tokenize(txt)\n",
    "for i in txt:\n",
    "     \n",
    "    # Word tokenizers is used to find the words\n",
    "    # and punctuation in a string\n",
    "    wordsList = nltk.word_tokenize(i)\n",
    " \n",
    "    # removing stop words from wordList\n",
    "    wordsList = [w for w in wordsList if not w in stop_words]\n",
    " \n",
    "    #  Using a Tagger. Which is part-of-speech\n",
    "    # tagger or POS-tagger.\n",
    "    tagged = nltk.pos_tag(wordsList)\n",
    "print(tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "2a3c8b02-84b9-45fb-92d4-0db5a4c9fd9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'roasted butternut squash bisque roasted butternut squash bisque could gluten free lacto ovo vegetarian recipe looking recipe serves 6 costs 5 1 per serving one serving contains 575 calories 6g protein 28g fat mixture coursely garlic salt bay leaves handful ingredients takes make recipe delicious recipe foodista 1 fans preparation plate recipe takes approximately approximately 45 minutes works well expensive soup taking factors account recipe earns spoonacular score 63 solid users liked recipe also liked roasted butternut squash bisque frangelico roasted butternut squash bisque sage cream butternut squash bisque garlic broth add ingredients stock bring boil reduce heat cover simmer 30 minutes strain cheesecloth use immediately soup freeze individual portions tip freezing broth ice cube trays allows use small portions time butternut squash soup cut squash half lengthwise scoop seeds quarter squash large place olive oil coated squash flesh side tray roasting roast top rack oven 425 degrees tender roughly 45 50 minutes sure use cookie tray least 1 2 inch lip squash give lot water pour generous amount olive oil cover bottom stock pot heat low medium heat add chopped onion cook translucent clean fennel bulb fern fern top finely leafed portion fennel cold water pat dry detach fern stems discarding stems pithy chop bulb discarding tough outer layer add chopped fennel bulb onion continue saut low heat stirring occasionally turn heat medium add 1 cup white wine onion fennel cook alcohol burns approximately 4 5 minutes seed quarter red bell peppers coat olive oil place cookie sheet flash side roast 20 minutes skins blistered started brown trick removing skins peppers remove peppers oven immediately place bowl cover cellophane let sit least 15 minutes skins peel easily meanwhile add vegetable garlic broth pot onions fennel cover bring slow boil mince several sage leaves add pot reduce simmer squash done scoop flesh peel add pot add remaining cup wine add cinnamon cayenne pepper curry powder ginger powder remove soup heat puree hand mixer immersion blender thoroughly mixed transfer food processor smoother texture many recipes call cream point create silkiness want bisque type soup little extra work eliminate need dairy products get creamy smooth texture without fat even silkier texture go one step work soup sieve spoon one completely okay texture soup without extra step garnish bowl leftover fennel fern enjoy extra virgin olive oil butter sweet onions fennel bulb butternut squash red bell pepper white wine fresh sage ginger powder cayenne pepper curry powder broth broth garlic bay leaves olive oil dried sage dried thyme oregano salt Produce Spices Seasonings Alcoholic Beverages Milk Eggs Other Dairy Spices Seasonings Produce Canned Jarred Oil Vinegar Salad Dressing gluten free lacto ovo vegetarian primal gluten-free lacto-ovo-vegetarian primal vegetarian gluten-free'"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8c24e0-231a-4bd9-b728-e952746a5722",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
